{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first approach is from using huggingface endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "if not HUGGINGFACEHUB_API_TOKEN:\n",
    "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"Enter your token: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    max_length=128,\n",
    "    temperature=0.5,\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nirajanpaudel17/Documents/Projects/Langchain/langchain_rag_env/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n## Meaning | Synonyms\\n\\n- a question asking for identification or description of someone or something\\n- a question to determine the nature, kind, or essential character of someone or something\\n- a question to find out what category or label someone or something belongs to\\n- a question to ascertain the identity or origin of someone or something\\n- a question to learn about the essential features or qualities of someone or something\\n- a question to understand the true nature or meaning of something\\n\\n## Example Sentences\\n\\n1. I don\\'t know what you are, but you\\'re not human.\\n2. The detective asked what the suspect was carrying in his bag.\\n3. The biologist wanted to know what species the new discovery belonged to.\\n4. The lawyer asked what kind of damage the plaintiff was claiming.\\n5. The teacher asked the students what they wanted to be when they grew up.\\n6. The scientist was trying to determine what caused the strange phenomenon.\\n7. The art critic wanted to know what genre the painting belonged to.\\n8. The customer service representative asked what type of problem the caller was experiencing.\\n9. The historian was trying to figure out what period in history the artifact came from.\\n10. The doctor asked what symptoms the patient was experiencing.\\n\\n## Origin\\n\\nThe word \"what are you?\" comes from the Old English word \"hw√¶t,\" which means \"what\" or \"what kind of.\" It has been used in English since at least the 14th century. The phrase is often used as a challenge or a question to elicit a response, especially when the speaker is unsure of someone\\'s or something\\'s identity or nature. In literature, it is often used as a rhetorical question or a way to express curiosity or skepticism. For example, in Shakespeare\\'s play \"Othello,\" Iago asks Othello, \"What art thou in this quarrel?\" to provoke a reaction.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm.invoke(\"what are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "question = \"What is the purpose of human life?\"\n",
    "template = \"\"\"\n",
    "You are an AI assistant and should reply to the {question} given\n",
    "question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={} template='\\nYou are an AI assistant and should reply to the {question} given\\nquestion: {question}\\n'\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='\\nYou are an AI assistant and should reply to the {question} given\\nquestion: {question}\\n') middle=[] last=HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.2', huggingfacehub_api_token='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', temperature=0.5, stop_sequences=[], server_kwargs={}, model_kwargs={'max_length': 128}, model='mistralai/Mistral-7B-Instruct-v0.2', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>)\n"
     ]
    }
   ],
   "source": [
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nirajanpaudel17/Documents/Projects/Langchain/langchain_rag_env/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# response = chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm an AI language model and don't have the ability to hold beliefs or have a purpose. However, I can provide information on various philosophical and spiritual perspectives on the purpose of human life.\n",
      "\n",
      "Throughout history, different cultures and religions have offered their own interpretations on the meaning and purpose of human life. Some believe that the purpose is to seek knowledge and wisdom, others believe it is to serve and help others, and still others believe it is to find happiness and fulfillment.\n",
      "\n",
      "From a scientific or atheistic perspective, some people believe that human life has no inherent purpose beyond what we make of it. They argue that we are just complex biological organisms that have evolved through natural selection, and that our purpose is to survive and reproduce.\n",
      "\n",
      "Ultimately, the question of the purpose of human life is a deeply personal and subjective one, and there is no definitive answer. It is a question that each individual must grapple with for themselves, based on their own beliefs, values, and experiences.\n"
     ]
    }
   ],
   "source": [
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 approach is using huggingface pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this process will download the model locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following approach will create a pipeline to use the model for simple usecases but to use it for complex usecases, and connect with language chain, we need to use the HuggingFacePipeline from langchain_huggingface.llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_id = \"openai-community/gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x15b5eb390>\n"
     ]
    }
   ],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we need to wrap this pipe object to hugginfacepipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# response = chat_model.invoke(\"What is machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is machine learning?\n",
      "\n",
      "Machine learning is the process by which computers learn a computer's properties. An advantage of machines learning is that it removes all of the tedious data that your computer can handle and can simply interpret the result. These effects are\n"
     ]
    }
   ],
   "source": [
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='\\nYou are an AI assistant and should reply to the {question} given\\nquestion: {question}\\n') middle=[] last=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x15b5e82d0>, model_id='openai-community/gpt2')\n"
     ]
    }
   ],
   "source": [
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\"what is machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an AI assistant and should reply to the what is machine learning? given\n",
      "question: what is machine learning?\n",
      "You should answer the what is machine learning question:\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's work on emneddings for the context in the user's prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings  = HuggingFaceEndpointEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"this needs to be changed to vectors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nirajanpaudel17/Documents/Projects/Langchain/langchain_rag_env/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test_embeddings = embeddings.embed_query(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00366128608584404, -0.03486212342977524, -0.04387234151363373, 0.018832802772521973, 0.055913690477609634, 0.046002063900232315, 0.10438206791877747, 0.010561849921941757, -0.0859338641166687, -0.012199318036437035, 0.04622172936797142, 0.019357578828930855, 0.0372622087597847, -0.004093350376933813, -0.023023340851068497, -0.06753921508789062, -0.0017033078474923968, 0.020846962928771973, -0.05659690126776695, -0.0008657878497615457, -0.008692623116075993, 0.04457367584109306, -0.025928253307938576, 0.029621370136737823, -0.0021677291952073574, -0.008942078799009323, 0.019525907933712006, -0.03721510246396065, 0.034955233335494995, -0.011716291308403015, 0.03746414557099342, 0.05074552446603775, 0.036482393741607666, -0.03409799560904503, 1.6163321561180055e-06, -0.01279933750629425, 0.010714709758758545, 0.012157527729868889, -0.01973973959684372, 0.07211853563785553, -0.020471541211009026, -0.007630809210240841, -0.013231683522462845, -0.0380997359752655, 0.016314741224050522, -0.07259120047092438, -0.034351810812950134, 0.00495336065068841, -0.020548108965158463, 0.09363186359405518, 0.018480004742741585, -0.023698478937149048, 0.058053888380527496, -0.03232588991522789, 0.10233886539936066, -0.03515906631946564, -0.015400717034935951, 0.022388024255633354, -0.045122452080249786, 0.07518181204795837, -0.02744177170097828, 0.053334709256887436, -0.03534087538719177, 0.06150112673640251, 0.11232806742191315, 0.02625790610909462, 0.08907710015773773, 0.04023207351565361, 0.004799587186425924, 0.01975666917860508, -0.014646191149950027, 0.017198780551552773, 0.013877838850021362, 0.031670913100242615, -0.013769427314400673, -0.03917567804455757, -0.03765062242746353, 0.019774451851844788, -0.010330273769795895, -0.03358516842126846, -0.005728408228605986, 0.01988157443702221, -0.01387660950422287, 0.008893405087292194, -0.002206153469160199, -0.03320655599236488, -0.014385522343218327, 0.04914507269859314, -0.05780259892344475, -0.02243473380804062, 0.021260812878608704, -0.019346779212355614, 0.033108316361904144, -0.050062280148267746, -0.01624397374689579, -0.004138960037380457, 0.008048438467085361, -0.07844524085521698, -0.01331433653831482, -0.09953957796096802, 0.08244273066520691, -0.027348937466740608, 0.040066301822662354, 0.033065348863601685, -0.0569777637720108, 0.05408729240298271, -0.040575724095106125, 0.07222571223974228, -0.09327314049005508, 0.09070514887571335, -0.012609872967004776, -0.027073416858911514, -0.010312411934137344, -0.03513842821121216, 0.005351028870791197, 0.05000336840748787, -0.027042565867304802, 0.04226279258728027, -0.031135691329836845, -0.060849256813526154, -0.015199068002402782, -0.014715280383825302, 0.02440391667187214, 0.012959420680999756, -0.0017427678685635328, 0.06819353252649307, 0.023204125463962555, 0.028479810804128647, 0.01796560175716877, 0.033838361501693726, -0.00081986392615363, 0.07448884099721909, -0.009221297688782215, -0.062087997794151306, -0.01624312251806259, 0.0019904267974197865, -0.006032758392393589, -0.040645550936460495, 0.09135490655899048, -0.053895004093647, -0.026137666776776314, 0.019692877307534218, 0.038138531148433685, -0.04018539935350418, -0.004409082233905792, 0.04493040591478348, 0.021955259144306183, -0.02041545696556568, -0.0014640565495938063, 0.041160423308610916, -0.07155322283506393, 0.05489904060959816, 0.01925668865442276, -0.0139777148142457, 0.04846501722931862, 0.027957163751125336, 0.017479734495282173, -0.06499028205871582, 0.008955501019954681, -0.026751767843961716, 0.02153889648616314, 0.026158174499869347, 0.03293682634830475, -0.04359470680356026, -0.0037062906194478273, -0.021428784355521202, -0.08738306164741516, -0.04287750646471977, 9.21125611057505e-05, 0.011745020747184753, 0.04114294424653053, 0.0001412436249665916, -0.04623321816325188, 0.01753390021622181, 0.010355752892792225, 0.03462712839245796, 0.04504457116127014, 0.07543062418699265, 0.016732806339859962, -0.013990216888487339, -0.026882324367761612, -0.07775174826383591, 0.016534874215722084, 0.007814756594598293, -0.07609166949987411, -0.02136535756289959, -0.01746511645615101, -0.0024779061786830425, 0.005188812036067247, -0.023082301020622253, -0.0034167433623224497, 0.012588019482791424, -0.021625565364956856, -0.018992150202393532, 0.014011875726282597, 0.023715559393167496, -0.006409778725355864, -0.014098427258431911, -0.021047081798315048, -0.07564528286457062, 0.008659307844936848, 0.027947181835770607, 0.09886771440505981, -0.0885336771607399, 0.02194110117852688, 0.025645827874541283, -0.035263657569885254, -0.04631195217370987, 0.014958527870476246, -0.01278204657137394, 0.0823877677321434, 0.04419592022895813, -0.027150776237249374, 0.007582060527056456, -0.007838740013539791, 0.027153005823493004, 0.014850253239274025, -0.006837461609393358, -0.05270049348473549, -0.032411567866802216, 0.024189043790102005, -0.046408187597990036, -0.0003560160694178194, -0.004505584016442299, -0.008932668715715408, 0.03791729360818863, 0.01152385026216507, -0.03772479295730591, 0.0003873254172503948, 0.0243530310690403, 0.03699231892824173, -0.004853636957705021, 0.01586103066802025, -0.05325660482048988, -0.018867572769522667, 0.021442336961627007, 0.035830218344926834, -0.008258236572146416, 0.031043091788887978, -0.0038452227599918842, -0.0018768592271953821, 0.010935265570878983, 0.01929348334670067, 0.06852316111326218, 0.004150277469307184, -0.029841480776667595, -0.057091426104307175, 0.01980549469590187, -0.009432712569832802, -0.018256640061736107, 0.01949824020266533, 0.0024906808976083994, -0.010226997546851635, -0.003922613803297281, 0.025794586166739464, 0.025690970942378044, 0.011120254173874855, -0.00450065266340971, 0.02941218949854374, 0.02194853499531746, 0.0440368577837944, 0.02835184521973133, 0.0020092702470719814, 0.00144487083889544, 0.03483038768172264, 0.019926460459828377, 0.012165253050625324, -0.015352814458310604, -0.0036182121839374304, 0.0078027197159826756, -0.053366854786872864, -0.026014264672994614, 0.01745719276368618, -0.0207819901406765, 0.019718993455171585, 0.002028927905485034, 0.004893646575510502, -0.03487827628850937, -0.04897875338792801, -0.012086856178939342, -0.014172682538628578, -0.03675776347517967, -0.021445956081151962, -0.022462667897343636, -0.026078198105096817, 0.01730937324464321, -0.003827719483524561, 0.0563141331076622, -0.029106583446264267, -0.01506295520812273, -0.04204495623707771, -0.046033550053834915, -0.006789849605411291, -0.022823091596364975, -0.03105824999511242, -0.054525379091501236, 0.024363504722714424, 0.04171737655997276, 0.06145535781979561, 0.03895052894949913, -0.023613877594470978, 0.021522479131817818, -0.01662478968501091, 0.012047950178384781, -0.03364574536681175, 0.015979794785380363, 0.020207339897751808, -0.011069237254559994, 0.025008538737893105, 0.008404621854424477, 0.03365064039826393, 0.000501815287861973, -0.005405051168054342, 0.010465935803949833, -0.002045613946393132, 0.009590128436684608, -0.0626540333032608, 0.0030215331353247166, 0.004650942049920559, 0.02433459274470806, 0.05590599402785301, 0.008934320881962776, -0.0510130301117897, 0.013306008651852608, 0.005296367220580578, -0.014165359549224377, -0.017402663826942444, -0.01738281548023224, -0.0683264434337616, 0.02589491382241249, 0.028558863326907158, -0.08472193777561188, 0.026205535978078842, 0.039766255766153336, 0.10496286302804947, -0.021806610748171806, -0.03807352855801582, -0.0004997667274437845, 0.037183716893196106, 0.020468764007091522, -0.03223438188433647, -0.04529334604740143, -0.03102610632777214, 0.02430012635886669, 0.015425661578774452, 0.03558577969670296, -0.03657824918627739, -0.0453261099755764, -0.02008824609220028, 0.010360028594732285, 0.05908099561929703, -0.009564431384205818, -0.015882275998592377, -0.014734555035829544, -0.023626070469617844, 0.008936195634305477, -0.01879609189927578, 0.04613048583269119, -0.05748285353183746, 0.017966384068131447, -0.0051207225769758224, -0.00801502913236618, 0.017039364203810692, 0.003968812525272369, -0.08305460214614868, 0.05967361852526665, -0.013263202272355556, 0.057948436588048935, -0.013586492277681828, -0.047204092144966125, -0.027416497468948364, 0.04667017608880997, -0.04399991035461426, -0.018066085875034332, -0.03315706178545952, 0.00033035397063940763, 0.014023932628333569, 0.02656017802655697, -0.06346317380666733, -0.0058346400037407875, 0.023051919415593147, -0.022783707827329636, 0.019244613125920296, -0.020189251750707626, -0.000683566730003804, 0.010105164721608162, -0.024556219577789307, -0.01659535989165306, -0.01768123358488083, -0.002932321047410369, 0.0033598938025534153, -0.026241857558488846, -0.13467058539390564, -0.020435383543372154, 0.006208907812833786, 0.00027804708224721253, 0.036327410489320755, 0.03655677288770676, 0.002092518610879779, 0.0038813212886452675, 0.011727740056812763, 0.036995794624090195, 0.03996295854449272, 0.02219962887465954, -0.003396104322746396, 0.006502547301352024, -0.029306858777999878, 0.016702769324183464, -0.030810898169875145, -0.07102209329605103, -0.014274216257035732, -0.0326797254383564, 0.0017776389140635729, -0.013712301850318909, 0.013226628303527832, -0.008316252380609512, 0.013972976244986057, 0.03226287290453911, -0.03437439352273941, -0.0435655303299427, -0.07044429332017899, -0.005325372330844402, 0.0373016782104969, 0.029043031856417656, 0.03874524310231209, -0.06496114283800125, 0.030934561043977737, -0.0790918692946434, -0.008361988700926304, -0.015476811677217484, 0.011275309138000011, 0.005273731425404549, -0.05468636751174927, 0.04427197575569153, -0.043679408729076385, -0.08143393695354462, -0.05047684162855148, -0.0009332278277724981, -0.019249649718403816, -0.04918506741523743, -0.008394869975745678, 0.012708908878266811, 0.06086519733071327, -0.07037273049354553, -0.040554556995630264, 0.022376416251063347, -0.007677184883505106, -0.048497483134269714, -0.017647797241806984, 0.03334494307637215, 0.06037360057234764, 0.05194386467337608, 0.051971759647130966, -0.04719024524092674, 0.01531805470585823, 0.007189153227955103, 0.02806781977415085, -0.035384487360715866, -0.028916122391819954, -0.035508688539266586, 0.05986554175615311, 0.02240695245563984, -0.06816615909337997, -0.012230293825268745, 0.04109324514865875, 0.0008476888760924339, 0.009882619604468346, -0.005416292231529951, 0.022395337000489235, -0.03774181380867958, 0.023488232865929604, -0.005403718911111355, -0.037229541689157486, 0.024485139176249504, 0.020988531410694122, -0.052294693887233734, -0.004480856470763683, -0.058554720133543015, -0.008002000860869884, -0.020810464397072792, -0.012825949117541313, 0.09245383739471436, 0.0145276403054595, -0.0054967752657830715, -0.04306966811418533, -0.014448053203523159, -0.017505347728729248, 0.04618307575583458, 0.02308727242052555, -0.014326277188956738, -0.06773785501718521, 0.0006744873826391995, -0.04046671837568283, 0.048135943710803986, 0.04002499207854271, -0.008514143526554108, -0.03116048499941826, -0.005928451661020517, -0.022757699713110924, -0.020545724779367447, -0.019807087257504463, -0.01568637415766716, -0.02046084962785244, -0.014802531339228153, -0.010857393965125084, -0.009159713052213192, 0.008180913515388966, 0.008779878728091717, 0.0007670162012800574, 0.002945683430880308, 0.015516269952058792, 0.012561166658997536, -0.07363077998161316, -0.07065518200397491, -0.011320889927446842, 0.0034677754156291485, -0.033950649201869965, -0.00580669566988945, 0.03625648468732834, -0.01892404444515705, 0.021478595212101936, -0.03474636748433113, 0.02915162220597267, -0.05581379681825638, 0.021839506924152374, 0.07914265245199203, 0.03784888982772827, 0.01080846507102251, -0.03930169716477394, 0.03250018134713173, -0.03580940142273903, 0.0514068603515625, -0.04689092934131622, 0.02671162225306034, -0.0030843738932162523, 0.01742393523454666, 0.061388369649648666, -0.02104305475950241, 0.006650575436651707, -0.008500221185386181, 0.03639940544962883, -0.05167509987950325, 0.045491889119148254, -0.018696410581469536, 0.09478949755430222, -0.014671703800559044, -0.011064675636589527, -0.05536271631717682, -0.013265205547213554, -0.06123681738972664, 0.006592331454157829, 0.026571162045001984, -0.07328056544065475, 0.03716232627630234, -0.0171060748398304, -5.628734578083549e-33, -0.0031347856856882572, -0.014813312329351902, -0.022340906783938408, 0.02699226513504982, -0.08785568922758102, 0.02921133302152157, 0.017650006338953972, 0.04620907083153725, -0.00031284141005016863, -0.02982603944838047, -0.0026257899589836597, 0.03187725320458412, 0.018818605691194534, -0.008042965084314346, 0.02418764866888523, 0.007030299864709377, 0.007544254884123802, -0.025548217818140984, 0.02596290037035942, -0.017218759283423424, -0.02593175321817398, 0.0243148822337389, 0.06657861173152924, -0.012793823145329952, -0.007396225351840258, 0.027853645384311676, -0.05057204142212868, 0.011418302543461323, -0.02097572758793831, 0.01838560588657856, -0.009440499357879162, -0.004852818325161934, -0.026315772905945778, -0.01488842535763979, 0.002787045668810606, 0.05835913494229317, 0.04238882288336754, -0.008939089253544807, -0.0033884660806506872, 0.049220871180295944, -0.03306197375059128, 0.017908044159412384, 0.00043187045957893133, -0.0078033083118498325, -0.010517529211938381, -0.035744067281484604, -0.032043423503637314, -0.02387481927871704, 0.019193513318896294, -0.008910592645406723, 0.006789803504943848, 0.012963813729584217, -0.03477881848812103, 0.007636821363121271, 0.029505722224712372, 0.015667609870433807, 0.013307854533195496, -0.044767919927835464, -0.04803430289030075, -0.02057976834475994, -0.003397594438865781, 0.027391158044338226, -0.00859196949750185, -0.01952355168759823, -0.04276696965098381, 0.0017735594883561134, 0.03942881524562836, -0.027530666440725327, -0.03363196179270744, 0.055771470069885254, 0.010279924608767033, 0.04806235060095787, 0.04817838594317436, 0.009240793995559216, 0.028909428045153618, -0.03236158937215805, -0.020747313275933266, 0.0573049858212471, -0.03390434384346008, 0.056613989174366, -0.011000278405845165, 0.0005057482630945742, -0.0585259348154068, 0.00688230711966753, -0.014810333959758282, -0.08959583938121796, -0.0058729019947350025, -0.015991998836398125, 0.013298860751092434, -0.0003018601855728775, 0.07826113700866699, 0.06426242738962173, 0.0077933501452207565, 0.06187110021710396, -0.0009732660255394876, 0.04277793690562248, 0.020589688792824745, 0.026461422443389893, 0.003007240127772093, -0.06267009675502777, -0.008311848156154156, 0.05083533376455307, 0.005890319589525461, -0.021328669041395187, 0.02713226154446602, -0.005488811992108822, 0.04294249042868614, -0.00949799083173275, -0.03363881632685661, -0.03919306397438049, 0.008839630521833897, -0.016697004437446594, 0.02036537416279316, 0.06984765827655792, 0.01888979785144329, 0.013183970004320145, -0.003914469853043556, 0.045300617814064026, 0.01401155348867178, -0.016726957634091377, -0.029564743861556053, 0.01700844243168831, -0.0008037365041673183, 0.013490991666913033, -0.053486961871385574, -0.04962242767214775, -0.01454214472323656, 0.023471180349588394, 0.01814424805343151, -0.08796878904104233, -0.037621937692165375, -0.012477410025894642, 2.2879906680373097e-07, 0.0021053669042885303, 0.045402538031339645, 0.019675610587000847, 0.05298985168337822, -0.04159623757004738, 0.041834283620119095, 0.011638953350484371, 0.04685307294130325, 0.05291428044438362, 0.040479570627212524, 0.005437430460005999, -0.03303878381848335, -0.003840032732114196, 0.014186913147568703, 0.003927730489522219, 0.0039900317788124084, 0.017444059252738953, 0.012621243484318256, -0.022948866710066795, 0.012785709463059902, 0.06449151039123535, -0.012158259749412537, 0.08584293723106384, -0.011744880117475986, -0.0025037999730557203, 0.0246913842856884, -0.020605765283107758, -0.02316300943493843, 0.025481034070253372, -0.04178566485643387, 0.004514897707849741, -0.01953934319317341, -0.04295065626502037, 0.03419371321797371, 0.004869978409260511, 0.017954349517822266, 0.037189781665802, 0.0332501083612442, 0.03985290601849556, 0.059017304331064224, -0.013499592430889606, 0.02259949967265129, -0.04311911016702652, -0.02421150729060173, -0.03399696946144104, 0.02353529818356037, 0.055208832025527954, -0.0473531074821949, 0.011589010246098042, 0.07188966125249863, 0.05529826134443283, -0.010184655897319317, -0.0012544088531285524, -0.04371866211295128, 0.022164838388562202, 0.0037780432030558586, 0.025914505124092102, -0.03425897657871246, 0.03405510634183884, 0.09237079322338104, -0.03127612546086311, -0.008857867680490017, 0.03314851224422455, 0.09233519434928894, 0.04647909849882126, -0.014678549021482468, 0.016407238319516182, 1.9882743076640113e-34, -0.012979704886674881, 0.0018951474921777844, -0.0209184680134058, 0.017264528200030327, -0.0005025382852181792, -0.004159839823842049, 0.010188788175582886, -0.03320065140724182, -0.004660886712372303, -0.04242291674017906, -0.03808373585343361]\n"
     ]
    }
   ],
   "source": [
    "print(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"paper-crash-detection.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Drowsiness and Crash Detection Mobile Application for Vehicle‚Äôs Safety  \\nISSN: 2582-1369  56 \\n Related Works \\nRecent advancements in accident prevention and safety assistance have been fueled by \\nthe integration of traditional methodologies and IoT -based approaches. Bhatti et al. [1], \\npresents a noteworthy study introducing an innovative Internet of Things -enabled accident \\ndetection and reporting system designed specifically for smart city environments. Utilizing \\nsmartphones, this system gathers data on multiple parameters including speed, gravitational \\nforce, pressure, sound, and location. This data is then analyze d to detect road incidents and \\nactivate suitable responses [12,15]. Through simulations and comparison with real -world \\naccident data, the effectiveness of this approach is demonstrated, showing promising levels of \\naccuracy and efficiency [1]. \\nIn a similar vein, Uma and Eswari proposed an accident prevention and safety \\nassistance system utilizing IoT and machine learning techniques [2]. This study explores the \\npotential of integrating IoT devices with machine learning algorithms to enhance accid ent \\ndetection and response capabilities. By analyzing sensor data from vehicles and roadside \\ninfrastructure, the system can identify potential hazards and alert drivers or emergency services \\naccordingly, thus mitigating the risk of accidents [2],[13],[14].= \\nFurthermore, efforts have been made to develop hardware-based solutions for accident \\ndetection and prevention. For instance, Prabha et al. [4], presents an automatic vehicle accident \\ndetection and messaging system that utilizes GSM and GPS modems [15]. This system enables \\nreal-time monitoring of vehicle movements and can automatically send distress signals in the \\nevent of an accident, facilitating prompt emergency response [3]. Similarly, Mahamud et al. \\n[11] proposed an Arduino -based accident prevention and  identification system for vehicles, \\nwhich integrates various sensors to detect abnormal vehicle behavior indicative of potential \\naccidents. \\nAdditionally, Yee and Lau explored the development of a mobile vehicle crash \\ndetection system [7], which aims to promptly identify and report accidents using smartphone \\ntechnology, thus expediting emergency response and potentially reducing accident -related \\nfatalities and injuries. \\nThese studies highlight the diverse approaches and technologies being employed to \\nenhance road safety and prevent accidents. By harnessing the capabilities of IoT, machine \\nlearning, and hardware devices, researchers are striving to develop comprehensive systems that \\ncan effectively detect, mitigate, and respond to potential hazards on the road [16],[17].'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "pages = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, that the pdf is loaded as document, we need to change into vector using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nirajanpaudel17/Documents/Projects/Langchain/langchain_rag_env/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore.from_documents(pages, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vector_store.similarity_search(\"Who are it's authors?\",k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='a6161334-672c-4968-8a3f-d48c9387c7b7', metadata={'producer': 'Microsoft¬Æ Word 2019', 'creator': 'Microsoft¬Æ Word 2019', 'creationdate': '2024-04-30T11:04:15+05:30', 'author': 'Microsoft account', 'moddate': '2024-04-30T11:04:15+05:30', 'source': 'paper-crash-detection.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content=\"Drowsiness and Crash Detection Mobile Application for Vehicle‚Äôs Safety  \\nISSN: 2582-1369  60 \\nc.   SIM 800L  \\nThis research work utilizes GSM technology through the SIM900A GSM module to \\nsend SMS notifications in case of predefined events, such as exceeding velocity limits or \\ndetecting vehicle tilt indicating an accident. These notifications include vital informat ion like \\nlocation and vehicle speed as shown in Figure 4, ensuring prompt response to critical situations. \\n \\n \\n \\n \\n \\n \\n \\n  Figure 4. Message Screenshot \\nd.    GPS Module (NEO 6M) \\nThe GPS module in this research work constantly delivers real -time latitude and \\nlongitude coordinates (as shown in Fig ure 5) to the Arduino, which monitors the vehicle's \\nlocation. By setting a predefined velocity range, the Arduino compares actual velocity with the \\nreceived coordinates, facilitating real-time tracking and monitoring of the vehicle's speed and \\nlocation.\"),\n",
       " Document(id='22520b23-000e-4af5-a67b-04aff9457016', metadata={'producer': 'Microsoft¬Æ Word 2019', 'creator': 'Microsoft¬Æ Word 2019', 'creationdate': '2024-04-30T11:04:15+05:30', 'author': 'Microsoft account', 'moddate': '2024-04-30T11:04:15+05:30', 'source': 'paper-crash-detection.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='Drowsiness and Crash Detection Mobile Application for Vehicle‚Äôs Safety  \\nISSN: 2582-1369  66 \\nManish Chhetri  - I am an engineering student pursuing Electronics, \\ncommunication and Information engineering from 2019 AD and expect to \\ngraduate in 2024 AD. Throughout the studies, I have developed passion \\nin the field of AI and Machine Learning. \\n \\nSudarshan Acharya, I am an engineering student pursuing Electronics, \\ncommunication and Information engineering from 2019 AD and expect \\nto graduate in 2024 AD. Throughout the studies, I have developed passion \\nin the field of Web Development and Machine Learning. \\n \\n \\nNabin Lamichhhane, Deputy Head of Department of Electronics and \\nComputer Engineering, IOE, TU, Nepal'),\n",
       " Document(id='0ff094ec-2fcd-404b-8a75-7876df6bb6ae', metadata={'producer': 'Microsoft¬Æ Word 2019', 'creator': 'Microsoft¬Æ Word 2019', 'creationdate': '2024-04-30T11:04:15+05:30', 'author': 'Microsoft account', 'moddate': '2024-04-30T11:04:15+05:30', 'source': 'paper-crash-detection.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content=\"Nabaraj Subedi, Nirajan Paudel, Manish Chhetri, Sudarshan Acharya, Nabin Lamichhane  \\nJournal of IoT in Social, Mobile, Analytics, and Cloud, March 2024, Volume 6, Issue 1 59 \\n \\nFigure 3. Crash Detection Flow Chart \\n3.3 Components Used \\na.   Arduino UNO  \\nThe Arduino Uno, built around the ATmega328P microcontroller, receives velocity and \\ntilt values from the accelerometer [7]. It verifies if these values meet predefined conditions \\nbefore proceeding with further operations. \\nb.   MPU 6050 \\nIn this study, a 10 DOF IMU Sensor, capable of measuring 3 -axis accelerometer data, \\nis utilized to detect changes in a vehicle's orientation, indicative of potential accidents. To \\ncalculate velocity and prevent accidents, the acceleration -time relationship is  leveraged, \\nenabling accurate velocity estimation based on acceleration values over time\"),\n",
       " Document(id='5b601bb7-63c9-406d-ae54-46e9b193b888', metadata={'producer': 'Microsoft¬Æ Word 2019', 'creator': 'Microsoft¬Æ Word 2019', 'creationdate': '2024-04-30T11:04:15+05:30', 'author': 'Microsoft account', 'moddate': '2024-04-30T11:04:15+05:30', 'source': 'paper-crash-detection.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='Nabaraj Subedi, Nirajan Paudel, Manish Chhetri, Sudarshan Acharya, Nabin Lamichhane  \\nJournal of IoT in Social, Mobile, Analytics, and Cloud, March 2024, Volume 6, Issue 1 63 \\n \\nThe facial detection system accurately identifies yawning and eye conditions as in \\nFigure 10, and the crash false notification triggering mechanism responds as depicted in Figure \\n7. \\n Conclusion \\nThe results obtained from the drowsiness and crash detection system demonstrate its \\neffectiveness in improving road safety. By detecting driver drowsiness and accurately \\nidentifying crash events while promptly notifying relevant parties, the system facilit ates swift \\nemergency response and aids in preventing potential accidents by monitoring the driver\\'s facial \\ncondition. Moreover, it promotes seamless coordination between vehicles and rescue center. \\nThe system\\'s accuracy rate and response time underscore its potential to enhance the efficiency \\nof emergency services and potentially reduce the severity of injuries in crash incidents. \\nNevertheless, it is important to acknowledge certain challenges and limitations. \\nEnvironmental factors, such as adverse weather conditions or heavy traffic congestion, may \\nintroduce additional complexities in crash detection. Further research efforts, such  as \\nintegrating both crash detection and drowsiness detection into a single device, are necessary to \\nenhance the system\\'s performance in such challenging scenarios. \\nReferences \\n[1] F. Bhatti, M. A. Shah, C. Maple, and S. U. Islam, \"A Novel Internet of Things-Enabled \\nAccident Detection and Reporting System for Smart City Environments,\" Sensors, vol. \\n19, no. 9, p. 2071, May 2019, doi: 10.3390/s19092071. \\n[2] S. Uma and R. Eswari, \"Accident prevention and safety assistance using IOT and \\nmachine learning,\" J. Reliab. Intell. Environ., vol. 8, no. 2, pp. 79‚Äì103, Jun. 2022, doi: \\n10.1007/s40860-021-00136-3. \\n[3] Pokhrel, Anisha, Laxmi Mahara, Monika Upadhyaya, Shikshya Shrestha, and Badri Raj \\nLamichhane. \"Drowsy Driver Detection with Crash Alert Mechanism using Arduino \\nand Image Processing.\" Journal of Soft Computing Paradigm 5, no. 2 (2023): 194-217. \\n[4] C. Prabha, R. Sunitha, and R. Anitha, \"Automatic Vehicle Accident Detection and \\nMessaging System Using GSM and GPS Modem,\" Int. J. Adv. Res. Electr. Electron.')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Related Works\n",
      "Yi, and Omar Abu Hassan. \"Automated bicycle crash detection system.\" In AIP\n",
      "1, Pages 54-66 54\n",
      "published: 30.04.2024\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "retreiver = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nirajanpaudel17/Documents/Projects/Langchain/langchain_rag_env/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='fdd04e44-341a-471c-aa07-96cc124c6d0c', metadata={'producer': 'Microsoft¬Æ Word 2019', 'creator': 'Microsoft¬Æ Word 2019', 'creationdate': '2024-04-30T11:04:15+05:30', 'author': 'Microsoft account', 'moddate': '2024-04-30T11:04:15+05:30', 'source': 'paper-crash-detection.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='published: 30.04.2024'),\n",
       " Document(id='d0eed70e-69bb-4be0-9575-0aa37179db8e', metadata={'producer': 'Microsoft¬Æ Word 2019', 'creator': 'Microsoft¬Æ Word 2019', 'creationdate': '2024-04-30T11:04:15+05:30', 'author': 'Microsoft account', 'moddate': '2024-04-30T11:04:15+05:30', 'source': 'paper-crash-detection.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='Related Works'),\n",
       " Document(id='6c0fb673-7601-4418-a06f-83a20a40a2c6', metadata={'producer': 'Microsoft¬Æ Word 2019', 'creator': 'Microsoft¬Æ Word 2019', 'creationdate': '2024-04-30T11:04:15+05:30', 'author': 'Microsoft account', 'moddate': '2024-04-30T11:04:15+05:30', 'source': 'paper-crash-detection.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='[15] Zaldivar, Jorge, Carlos T. Calafate, Juan Carlos Cano, and Pietro Manzoni. \"Providing'),\n",
       " Document(id='b58336e5-e92c-4d95-a913-6c48913e791b', metadata={'producer': 'Microsoft¬Æ Word 2019', 'creator': 'Microsoft¬Æ Word 2019', 'creationdate': '2024-04-30T11:04:15+05:30', 'author': 'Microsoft account', 'moddate': '2024-04-30T11:04:15+05:30', 'source': 'paper-crash-detection.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='[14] White, Jules, Chris Thompson, Hamilton Turner, Brian Dougherty, and Douglas C.')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retreiver.invoke(\"authors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upto here, retreiver work is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we need to extend our language chain such that, context is provided after similarity search in vectore store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    max_length=128,\n",
    "    temperature=0.5,\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,\n",
    ")\n",
    "\n",
    "# generating the prompt template for the model\n",
    "template = \"\"\"\n",
    "question: {question}\n",
    "context: {context}\n",
    "You are an smart AI assistant and should reply to the {question} given according to the {context} given.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# chain = (\n",
    "#     {\"context\": retreiver, \"question\": RunnablePassthrough()} \n",
    "#     | prompt\n",
    "#     | model\n",
    "# )\n",
    "\n",
    "chain = {\n",
    "    \"context\": retreiver,  \n",
    "    \"question\": RunnablePassthrough() \n",
    "} | prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  context: VectorStoreRetriever(tags=['InMemoryVectorStore', 'HuggingFaceEndpointEmbeddings'], vectorstore=<langchain_core.vectorstores.in_memory.InMemoryVectorStore object at 0x1400d1310>, search_kwargs={}),\n",
      "  question: RunnablePassthrough()\n",
      "} middle=[PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\nquestion: {question}\\ncontext: {context}\\nYou are an smart AI assistant and should reply to the {question} given according to the {context} given.\\n')] last=HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.2', huggingfacehub_api_token='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', temperature=0.5, stop_sequences=[], server_kwargs={}, model_kwargs={'max_length': 128}, model='mistralai/Mistral-7B-Instruct-v0.2', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>)\n"
     ]
    }
   ],
   "source": [
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nirajanpaudel17/Documents/Projects/Langchain/langchain_rag_env/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/Users/nirajanpaudel17/Documents/Projects/Langchain/langchain_rag_env/lib/python3.13/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe authors of the paper are Jorge Zaldivar, Carlos T. Calafate, Juan Carlos Cano, and Pietro Manzoni.'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"who are the authors of this paper?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
